{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e83d30-5c3b-4690-93c7-32bee946e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89de0ac-e011-4712-bc28-418b060f1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem data\n",
    "model_proportion_candidate1 = 0.4860\n",
    "model_proportion_candidate2 = 0.4870\n",
    "actual_proportion = 0.4832\n",
    "\n",
    "# Sample sizes\n",
    "n1 = 18  # Model sample size\n",
    "n2 = 155238302  # Actual sample size (total number of votes)\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7303ab-2077-4b16-a063-9f9fd4cd5a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Model Candidate 1 (48.60%) vs. Actual Value (48.32%)\n",
      "proportion_difference: 0.002800\n",
      "z_statistic: 0.023772\n",
      "p_value: 0.981034\n",
      "z_critical: 1.959964\n",
      "conclusion: Fail to reject H0: No evidence that the proportions are different (p-value = 0.981034 > 0.05)\n",
      "P-value interpretation: No significant difference (p > 0.05)\n",
      "\n",
      "Test 2: Model Candidate 2 (48.70%) vs. Actual Value (48.32%)\n",
      "proportion_difference: 0.003800\n",
      "z_statistic: 0.032262\n",
      "p_value: 0.974263\n",
      "z_critical: 1.959964\n",
      "conclusion: Fail to reject H0: No evidence that the proportions are different (p-value = 0.974263 > 0.05)\n",
      "P-value interpretation: No significant difference (p > 0.05)\n",
      "\n",
      "Test 3: Model Candidate 1 (48.60%) vs. Model Candidate 2 (48.70%)\n",
      "proportion_difference: -0.001000\n",
      "z_statistic: -0.006000\n",
      "p_value: 0.995213\n",
      "z_critical: 1.959964\n",
      "conclusion: Fail to reject H0: No evidence that the proportions are different (p-value = 0.995213 > 0.05)\n",
      "P-value interpretation: No significant difference (p > 0.05)\n",
      "\n",
      "Executing calculations...\n",
      "\n",
      "P-values Summary:\n",
      "Model 1 vs. Actual: 0.9810343076\n",
      "Model 2 vs. Actual: 0.9742628866\n",
      "Model 1 vs. Model 2: 0.9952127214\n"
     ]
    }
   ],
   "source": [
    "# Function to perform the proportions test\n",
    "def test_proportions(p1, p2, n1, n2, alpha):\n",
    "    # Convert proportions to counts\n",
    "    x1 = round(p1 * n1)\n",
    "    x2 = round(p2 * n2)\n",
    "    \n",
    "    # Calculate pooled proportion\n",
    "    p_pooled = (x1 + x2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate standard error\n",
    "    std_error = np.sqrt(p_pooled * (1 - p_pooled) * (1/n1 + 1/n2))\n",
    "    \n",
    "    # Calculate z-statistic\n",
    "    z = (p1 - p2) / std_error\n",
    "    \n",
    "    # Calculate p-value (two-tailed test)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    # Critical value for alpha = 0.05 (two-tailed)\n",
    "    z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # Determine conclusion based on p-value\n",
    "    if p_value < alpha:\n",
    "        conclusion = \"Reject H0: The proportions are statistically different (p-value < 0.05)\"\n",
    "    else:\n",
    "        conclusion = f\"Fail to reject H0: No evidence that the proportions are different (p-value = {p_value:.6f} > 0.05)\"\n",
    "    \n",
    "    return {\n",
    "        \"proportion_difference\": p1 - p2,\n",
    "        \"z_statistic\": z,\n",
    "        \"p_value\": p_value,\n",
    "        \"z_critical\": z_critical,\n",
    "        \"conclusion\": conclusion\n",
    "    }\n",
    "\n",
    "# Perform the tests\n",
    "print(\"Test 1: Model Candidate 1 (48.60%) vs. Actual Value (48.32%)\")\n",
    "result1 = test_proportions(model_proportion_candidate1, actual_proportion, n1, n2, alpha)\n",
    "for key, value in result1.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "print(f\"P-value interpretation: {'Significant difference (p < 0.05)' if result1['p_value'] < alpha else 'No significant difference (p > 0.05)'}\")\n",
    "\n",
    "print(\"\\nTest 2: Model Candidate 2 (48.70%) vs. Actual Value (48.32%)\")\n",
    "result2 = test_proportions(model_proportion_candidate2, actual_proportion, n1, n2, alpha)\n",
    "for key, value in result2.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "print(f\"P-value interpretation: {'Significant difference (p < 0.05)' if result2['p_value'] < alpha else 'No significant difference (p > 0.05)'}\")\n",
    "\n",
    "# Compare the two models against each other\n",
    "print(\"\\nTest 3: Model Candidate 1 (48.60%) vs. Model Candidate 2 (48.70%)\")\n",
    "result3 = test_proportions(model_proportion_candidate1, model_proportion_candidate2, n1, n1, alpha)\n",
    "for key, value in result3.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "print(f\"P-value interpretation: {'Significant difference (p < 0.05)' if result3['p_value'] < alpha else 'No significant difference (p > 0.05)'}\")\n",
    "\n",
    "# Execute the code to see the actual results\n",
    "print(\"\\nExecuting calculations...\")\n",
    "# Display the calculated p-values explicitly\n",
    "print(\"\\nP-values Summary:\")\n",
    "print(f\"Model 1 vs. Actual: {result1['p_value']:.10f}\")\n",
    "print(f\"Model 2 vs. Actual: {result2['p_value']:.10f}\")\n",
    "print(f\"Model 1 vs. Model 2: {result3['p_value']:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9be444-a89a-4cec-b816-d2e7c6d85226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
